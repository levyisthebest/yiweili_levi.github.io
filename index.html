<!DOCTYPE HTML>
<html lang="en">

<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">


  <title>Yiwei Li</title>
  
  <meta name="author" content="Yiwei Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!--<link rel="icon" type="image/svg+xml" href="images/University_of_Georgia_seal.svg">-->
  <link rel="alternate icon" type="image/png" href="images/UGA_CS.png">

  <!-- <script src=”main.js” defer></script> -->
</head>

<body>
<!-- 
<div class="topnav" id="myTopnav">
  <a href="#Home">Home</a>
  <a href="#Research">Research</a>
  <a href="#Experience">Experience</a>
  <a href="#Education">Education</a>
  <a href="#Misc">Misc</a>
  <a href="javascript:void(0);" class="icon" onclick="myFunction()">
    <i class="fa fa-bars"></i>
  </a>
</div>

<script>
  function myFunction() {
    var x = document.getElementById("myTopnav");
    if (x.className === "topnav") {
      x.className += " responsive";
    } else {
      x.className = "topnav";
    }
  }
</script> -->
  <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:10px">
      <td style="padding:10px">

      <section id="Home" style="padding-top:2vh;padding-bottom:1vh;">       
              <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tr style="padding:10px">
                  <td style="padding:2.5%;width:63%;vertical-align:middle;line-height: 150%;">
                    <p style="text-align:center">
                      <name>Yiwei Li - 李轶为</name>
                    </p>
                    <p>
                      I am a second-year Ph.D. student at the University of Georgia, under the mentorship of Prof. <a href="https://cobweb.cs.uga.edu/~tliu/">Tianming Liu</a>. I graduated with a Bachelor's degree in Information Engineering from the Chien-Shiung Wu College at Southeast University (2016-2020). I then completed my Master's degree in the School of Computer Science at Southeast University (2020-2023), where I worked under the supervision of Prof. <a href="https://home.penglab.com/">Hanchuan Peng</a> with a focus on computational neuroscience. My research is centered around the exciting fields of <strong>AGI and Computational Neuroscience</strong>, with primary goal is to bridge the gap between AGI and the human brain, particularly in the context of multimodality, exploring the mechanisms behind human intelligence. I am also interested in <strong>AI4Med</strong>/<strong>AI4Sci</strong> and am currently a data scientist intern (remote) at <a href="https://camca.mgh.harvard.edu/about-us/">CAMCA</a>, Harvard Medical School. My specific areas of research include:
                      <ul>
                          <li><strong>Medical Video Generation:</strong> <a href="https://arxiv.org/html/2410.03143v1">ECHOPulse(ECG controlled ECHO video generation)</a>. </li>
                          <li><strong>Sim2Real:</strong> <a href="https://arxiv.org/abs/2403.11459">ALDMGrasping(Robot sim2real)</a>.</li>
                          <li><strong>Neuron Reconstrcution:</strong> <a href="https://academic.oup.com/bioinformaticsadvances/article/3/1/vbad054/7172445">NRRS(Solution to backbone deviation during neuron reconstruction)</a>.</li>
                          <li><strong>Medical Foundation Models:</strong> <a href="https://arxiv.org/abs/2403.12416">Eye-gaze Guided Multi-modal Alignment for Medical Representation Learning</a>. </li>
                      </ul>
                    </p>
                    <p style="color:#e74c3c; font-weight:bold; text-align:center; margin-top:10px;">I am actively seeking a research internship starting in Summer 2025.</p>
                    <p style="text-align:center">
                      <span style="white-space: nowrap;">
                        <i class="fa fa-envelope"></i> 
                        <a href="mailto:yl80817@uga.edu">UGA</a> / 
                        <a href="mailto:yili6@mgh.harvard.edu">Harvard</a>
                      </span>
                      &nbsp;&nbsp;|&nbsp;&nbsp;
                      <a href="https://www.linkedin.com/in/yiwei-li-84708526b/"><i class="fa fa-linkedin"></i> LinkedIn</a>
                      &nbsp;&nbsp;|&nbsp;&nbsp;
                      <a href="https://scholar.google.com/citations?user=sfEPWiAAAAAJ&hl=en"><i class="fa fa-graduation-cap"></i> Google Scholar</a>
                      &nbsp;&nbsp;|&nbsp;&nbsp;
                      <a href="https://github.com/levyisthebest"><i class="fa fa-github"></i> GitHub</a>
                      &nbsp;&nbsp;|&nbsp;&nbsp;
                      <a href="https://github.com/levyisthebest/yiweili_levi.github.io/blob/main/Yiwei_Li_Resume_Spring_2025.pdf" target="_blank"><i class="fa fa-file-text-o"></i> CV</a>
                    </p>  
                  </td>
                  <td style="padding:2.5%;width:25%;max-width:25%">
                    <a href="images/Yiwei.jpg"><img style="width:100%;max-width:100%" alt="info photo" src="images/Yiwei.jpg" class="hoverZoomLink"></a>
                  </td>
                </tr>
              </tbody></table>
              </section>

        <section id="News">
            <h2 style="padding-bottom:1vh;"> News </h2>
            <table style="line-height:150%" class="table table-hover table-striped">
                <tr><td style="width:20%;">2025/1 - One paper accepted by ICLR 2025. </td></tr>
                <tr><td style="width:20%;">2025/1 - One paper accepted by ICRA 2025. </td></tr>
                <tr><td style="width:20%;">2024/12 - One paper accepted by ISBI 2025. </td></tr>
                <tr><td style="width:20%;">2024/10 - One paper accepted by PLoS Global Health. </td></tr>
                <tr><td style="width:20%;">2024/09 - One paper accepted by NeurIPS 2024. </td></tr>
                <tr><td style="width:20%;">2024/05 - Starting my remote internship at Harvard Medical School, advised by Dr. <a href="https://xiangli-shaun.github.io/index.html">Xiang Li. </td></tr>
                <tr><td style="width:20%;">2024/04 - One paper accepted by MICCAI 2024. </td></tr>
                <tr><td style="width:20%;">2023/08 - I joined the CAID lab at the University of Georgia as a research assistant. </td></tr>
            </table>
        </section>

        <br>

        <br>

        <section id="Research">
        <h2> Selected Papers </h2>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="text-indent:20px;width:100%;vertical-align:middle">
        <p>
          *Equal contribution.
        </p>
        </td>
        </tr>
        </tbody></table>

        <h3 style="text-indent:20px;color:#4A90E2;border-bottom:2px solid #4A90E2;padding-bottom:5px;">Video Generation</h3>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <!-- Paper entries for Interpretable AI System Design -->
          <!-- (Paper entries omitted for brevity) -->
        

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:10px;width:20%;vertical-align:middle">
                <img src="images/ICLR_ECHOPulse.png" alt="hpp" style="border-style: none" width="220">
              </td>
              <td style="padding:10px;width:80%;vertical-align:middle">
                <p>
                <papertitle>ECHOPulse: ECG Controlled Echocardiograms Video Generation</papertitle>
                </p>
                <strong>Yiwei Li*</strong>, Sekeun Kim*, Zihao Wu, Hanqi Jiang, Yi Pan, Pengfei Jin, Sifan Song, Yucheng Shi, Xiaowei Yu, Tianze Yang, Tianming Liu, Quanzheng Li, Xiang Li.
                <br>
                <em><strong>(ICLR 2025)</strong>, The Thirteenth International Conference on Learning Representations, 2025.</em>
                <br>
                <a href="https://arxiv.org/html/2410.03143v1">[Paper]</a>
                <a href="https://github.com/levyisthebest/ECHOPulse_Prelease">[code]</a> 
        </tbody></table>


        
        <h3 style="text-indent:20px;color:#50C878;border-bottom:2px solid #50C878;padding-bottom:5px;">Neuron Reconstruction</h3>  

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <!-- Paper entries for Reliability and Safety -->
          <!-- (Paper entries omitted for brevity) -->
         

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:10px;width:20%;vertical-align:middle">
                <img src="images/NRRS.png" alt="hpp" style="border-style: none" width="220">
              </td>
              <td style="padding:10px;width:80%;vertical-align:middle">
                <p>
                <papertitle>NRRS: a re-tracing strategy to refine neuron reconstruction</papertitle>
                </p>
                <strong>Yiwei Li</strong>, Shengdian Jiang, Liya Ding, Lijuan Liu.
                <br>
                <em><strong>Bioimage informatics</strong>.</em>
                <br>
                <a href="https://watermark.silverchair.com/vbad054.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAA5YwggOSBgkqhkiG9w0BBwagggODMIIDfwIBADCCA3gGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMPcBIcz3C3XglrSTfAgEQgIIDSb3aVHzpZ8-1k7ZEFGsD3Zkd54-3Fpy2pxAi7KFod6pB6_p7zSY5l_SyzfqDj5d6rOfKYu-H44r5ryE0r00mt4xfYK8mRZKkuZ1Amv9697tDVHmS9Io3amomDZ0yBU6mOV7kgR_Ls69n4n4p_LejTLC_dtUaLtFrzXmh3zqZcHlcX3wANpAPyrOhwIbFQwo3CW2eV5ldW6ms6xOxKBwqLYfzrk_sKoIeREaDeaOL1IpcEtzMJ47_sLd089y1haCptYgdml0beAOMJzUQf8tzdJZe8h-gEjfrKStvDyfEuXN774mQzdikfT-X7W2D-xxLzgsqGXY48GEsdst1rDH6jx89K52vusuCBqsdSrOY6hsfdyHuhv0DfWkZ6CheHGciGhHuIA0BP9CR8sLXslosLtR-jTGzwqUgDXlfZN1qr1x2NaoPn28UX_9RFQItnhHq8s_thmyKKwYz1S5DSeDZR4TGp_RqggKAMnj2Z-_d47wXdPO6CX16yhaVMyXEoFPwjuRhBN_Reb0gFLgoOvubOJnraDdwlW29y70ieyIQT3LzBQdM1alzTpa9mOh1TkZS7tkqLJdImtx0Wqn4TIbEQbte1g5n9aomWpx78k_hlSHGI3FRfjoBPvCjx1z8Qz4vFzn2-C18wrgH7Fak-0zZMVdLt4vHbwh3onOFjqd5jypxgxdZKVrkcObOFQUEHa5UgypI9A4lsDTQ1ZIf2A2mmaB5QM_KRu8iAfHOcyLe7XgOKJ9ThcGGE9m82wDX1U_ijFVkTZMVp7w3jJ4H5U5RBFHY9a4-PV8Lu9x9vQ7fG_-omDXLaUsudexHtfpn5FfLtPntudH8GkGB7QgNd0jvoAqPFTfEE3T1tSOUjm4m3xo6cmL9GsingQXsZ47kSFjW3we1n0FnW5r_DXUc02wC87k0EIBctSLOT_ToYf2sOtnp6dn_bu4asoy5GSMVJrpgJydWvaA-Ra8vDAlXb-C8_9r5UlFStqXxmN_W6az3YmVe6VvkhjwLdqd1Z_DJ8yuvKWQk97p_ZxD4ptU54atlG76XBSgrsz1zTUlI0F3arLgvf8wFoKk3ceGppeR6PSIiFPQFNOuhxlSKpxOZ5vQevPZ4hI6zWesdTWE">[Paper]</a>
                <a href="https://github.com/Vaa3D/vaa3d_tools/tree/master/hackathon/Levy/refinement">[code]</a>  
        </tbody></table>
          
        <h3 style="text-indent:20px;color:#F39C12;border-bottom:2px solid #F39C12;padding-bottom:5px;">LLM agents</h3> 

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <!-- Paper entries for Explainability and its utilization -->
          <!-- (Paper entries omitted for brevity) -->
        

           <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:10px;width:20%;vertical-align:middle">
                <img src="images/AD_AutoGPT.png" alt="hpp" style="border-style: none" width="220">
              </td>
              <td style="padding:10px;width:80%;vertical-align:middle">
                <p>
                <papertitle>AD-AutoGPT: An Autonomous GPT for Alzheimer's Disease Infodemiology</papertitle>
                </p>
                Haixing Dai<sup>*</sup>, <strong>Yiwei Li<sup>*</sup></strong>strong>, Zhengliang Liu, Lin Zhao, Zihao Wu, Suhang Song, Ye Shen, Dajiang Zhu, Xiang Li, Sheng Li, Xiaobai Yao, Lu Shi, Quanzheng Li, Zhuo Chen, Donglan Zhang, Gengchen Mai, Tianming Liu.	
                <br>
                <em><strong>PLoS Public Health</strong></em>
                <br>
                <a href="https://arxiv.org/abs/2306.10095">[Paper]</a>
                <a href="https://github.com/levyisthebest/AD-AutoGPT">[code]</a>              
                
        </tbody></table>


        <h3 style="text-indent:20px;color:#8E44AD;border-bottom:2px solid #8E44AD;padding-bottom:5px;">Multimodality Alignment</h3>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">  
              <td style="padding:10px;width:20%;vertical-align:middle">
                  <img src="images/EyeGazed.png" alt="hpp" style="border-style: none" width="220">
                </td>
                <td style="padding:10px;width:80%;vertical-align:middle">
                  <p>
                  <papertitle>Eye-gaze Guided Multi-modal Alignment for Medical Representation Learning</papertitle>
                  </p>
                   Chong Ma, Hanqi Jiang, Wenting Chen, <strong>Yiwei Li</strong>, Zihao Wu, Xiaowei Yu, Zhengliang Liu, Lei Guo, Dajiang Zhu, Tuo Zhang, Dinggang Shen, Tianming Liu, Xiang Li.
                  <br>
                    <em><strong>(NeurIPs)</strong>, The Thirty-eighth Annual Conference on Neural Information Processing Systems, 2024.</em>
                  <br>
                  <a href="https://openreview.net/forum?id=0bINeW40u4">[Paper]</a>
                  <a href="https://github.com/MoMarky/EGMA">[code]</a> 
        </tbody></table>
        </section>

        <br>
                
<!--         <section id="Teaching">
        <h2 style="padding-bottom:1vh;">Teaching</h2>
        <table style="line-height:150%" class="table table-hover table-striped">
          <tr><td style="width:20%;">Teaching Assistant of CSCI4380/6380 Data Mining and CSCI4370/6370 Database Management, University of Georgia, Spring 2024</td></tr>
          <tr><td style="width:20%;">Teaching Assistant of CSCI4380/6380 Data Mining (Two Sessions), University of Georgia, Fall 2023</td></tr>
          <tr><td style="width:20%;">Teaching Assistant of CSCI4380/6380 Data Mining, University of Georgia, Spring 2023</td></tr>
          <tr><td style="width:20%;">Teaching Assistant of CSCI4360/6360 Data Science, University of Georgia, Fall 2022</td></tr>
        </table> 
        </section> -->
        
        <br>

        <section id="Miscellaneous">
          <h2 style="padding-bottom:1vh;">Miscellaneous</h2>
          <div class="row">
            <div class="col-md-8">
              <p>
                Outside of research, I enjoy playing basketball and cooking. I also have an adorable cat called Rainbow.              
<!--                 <a href="https://www.flickr.com/photos/157896273@N06/" class="btn btn-primary" target="_blank">
                <i class="fa fa-flickr"></i> My Flickr.
                </a> -->
            </div>
          </div>
        </section>

        <br>

      </td>
    </tr>
  </table>
</body>

</html>
